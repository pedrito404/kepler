{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# str = !awk 'BEGIN {FS=\"/\"} {print $4}' k56_mod1_M60.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(arq[0])):\n",
    "#     exec(\"leitura_arquivo{0}= pd.read_csv(r,delim_whitespace=True,header =None,engine='c')\".format(i))\n",
    "#     exec(\"leitura_arquivo{0}.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\".format(i))\n",
    "#     exec(\"dfabarra1.append(np.mean(leitura_arquivo{0}['a']))\".format(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output - Arquivo list mem no caminho SWIFT/example\n",
    "# encoding utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sonic/SWIFT/example\r\n"
     ]
    }
   ],
   "source": [
    "#np.std()\n",
    "# print(np.mean([1,2]))\n",
    "# print(np.std([1,2],dtype=np.float64,ddof=1))\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['find: ‘k*60.txt’: Arquivo ou diretório não encontrado']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arquivos = !find k*60.txt -type f\n",
    "print(arquivos)\n",
    "#print(arq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'find: ‘k*60.txt’: Arquivo ou diretório não encontrado'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6210286275ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marquivos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0marq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'find: ‘k*60.txt’: Arquivo ou diretório não encontrado'"
     ]
    }
   ],
   "source": [
    "arq=[]\n",
    "for l in arquivos:\n",
    "    with open(l) as f:\n",
    "        arq.append(f.read().splitlines())\n",
    "for y in range(len(arq)):\n",
    "     arq[y] = np.sort(arq[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arq[0][0].split('/')[3]\n",
    "arq[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfconfig1=[]\n",
    "dfabarra1 =[]\n",
    "dfdeltaa1 =[]\n",
    "dfeinicial1 = []\n",
    "dfemax1 = []\n",
    "dfstable1 = []\n",
    "caminho1=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r in arq[0]:\n",
    "    dfconfig1.append(r.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "#    dfconfig1 = dfconfig1.replace(r'_', r'\\underline{\\space}')\n",
    "    leitura_arquivo = pd.read_csv(r,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra1.append('{:.6f}'.format(np.mean(leitura_arquivo['a'])))\n",
    "    #dfeinicial1.append(float(leitura_arquivo['e'][0]))\n",
    "    dfemax1.append('{:.5f}'.format(max(leitura_arquivo['e'])))\n",
    "#    dfdeltaa1.append('{:.3e}'.format(np.std(leitura_arquivo['a'],ddof=1)))\n",
    "    caminho1.append(r.split('f')[0])\n",
    "    \n",
    "for h in range(len(arq[0])):\n",
    "    with open(caminho1[h]+'discard_mass.out') as dis:\n",
    "        arq_dis = dis.read().splitlines()\n",
    "    if len(arq_dis) != 0:\n",
    "        primeiro = arq_dis[0].strip()\n",
    "        primeiro = primeiro.split()\n",
    "        dfstable1.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro[0]))+dias)\n",
    "    else:\n",
    "        dfstable1.append('Sim')\n",
    "\n",
    "#columns=['Configuração',r'$\\bar{a}$ (UA)',r'$\\sigma _{a}$ (UA)',r'e$_{ini}$',r'e$_{max}$','stable']\n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df1 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df1['Configuração']=dfconfig1\n",
    "df1[r'$\\bar{a}$ (UA)']= dfabarra1\n",
    "#df1[r'$\\sigma _{a}$ (UA)']= dfdeltaa1\n",
    "#df1[r'e$_{ini}$']=dfeinicial1\n",
    "df1[r'e$_{max}$']=dfemax1\n",
    "df1['Estável']=dfstable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab1 = open('tables/k56_mod1_M60.tex','w')\n",
    "tab1.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab1.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab1.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab1.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab1.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab1.write(r'\\begin{document}''\\n')\n",
    "tab1.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab1.write(df1.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab1.write(r'\\end{adjustbox}''\\n')\n",
    "tab1.write(r'\\end{document}''\\n')\n",
    "tab1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !cd tables/\n",
    "# !pwd\n",
    "# !texstudio k*.tex &\n",
    "# !cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfconfig2=[]\n",
    "dfabarra2 =[]\n",
    "dfdeltaa2 =[]\n",
    "dfeinicial2 = []\n",
    "dfemax2 = []\n",
    "dfstable2 = []\n",
    "caminho2=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r2 in arq[1]:\n",
    "    dfconfig2.append(r2.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "    leitura_arquivo2 = pd.read_csv(r2,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo2.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra2.append('{:.6f}'.format(np.mean(leitura_arquivo2['a'])))\n",
    "    #dfeinicial2.append(float(leitura_arquivo2['e'][0]))\n",
    "    dfemax2.append('{:.5f}'.format(max(leitura_arquivo2['e'])))\n",
    "#    dfdeltaa2.append('{:.3e}'.format(np.std(leitura_arquivo2['a'],ddof=1)))\n",
    "    caminho2.append(r2.split('f')[0])\n",
    "#    print(max(leitura_arquivo2['a']) - min(leitura_arquivo2['a']))\n",
    "for h2 in range(len(arq[1])):\n",
    "    with open(caminho2[h2]+'discard_mass.out') as dis2:\n",
    "        arq_dis2 = dis2.read().splitlines()\n",
    "    if len(arq_dis2) != 0:\n",
    "        primeiro2 = arq_dis2[0].strip()\n",
    "        primeiro2 = primeiro2.split()\n",
    "        dfstable2.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro2[0]))+dias)\n",
    "    else:\n",
    "        dfstable2.append('Sim')\n",
    "        \n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df2 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df2['Configuração']=dfconfig2\n",
    "df2[r'$\\bar{a}$ (UA)']= dfabarra2\n",
    "#df2[r'$\\sigma _{a}$ (UA)']= dfdeltaa2\n",
    "#df2[r'e$_{ini}$']=dfeinicial2\n",
    "df2[r'e$_{max}$']=dfemax2\n",
    "df2['Estável']=dfstable2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab2 = open('tables/k56_mod1_omega60.tex','w')\n",
    "tab2.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab2.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab2.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab2.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab2.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab2.write(r'\\begin{document}''\\n')\n",
    "tab2.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab2.write(df2.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab2.write(r'\\end{adjustbox}''\\n')\n",
    "tab2.write(r'\\end{document}''\\n')\n",
    "tab2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconfig3=[]\n",
    "dfabarra3 =[]\n",
    "dfdeltaa3 =[]\n",
    "dfeinicial3 = []\n",
    "dfemax3 = []\n",
    "dfstable3 = []\n",
    "caminho3=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r3 in arq[2]:\n",
    "    dfconfig3.append(r3.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "    leitura_arquivo3 = pd.read_csv(r3,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo3.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra3.append('{:.6f}'.format(np.mean(leitura_arquivo3['a'])))\n",
    "    #dfeinicial3.append(float(leitura_arquivo3['e'][0]))\n",
    "    dfemax3.append('{:.5f}'.format(max(leitura_arquivo3['e'])))\n",
    "#    dfdeltaa3.append('{:.3e}'.format(np.std(leitura_arquivo3['a'],ddof=1)))\n",
    "    caminho3.append(r3.split('f')[0])\n",
    "#    print(max(leitura_arquivo3['a']) - min(leitura_arquivo3['a']))\n",
    "for h3 in range(len(arq[2])):\n",
    "    with open(caminho3[h3]+'discard_mass.out') as dis3:\n",
    "        arq_dis3 = dis3.read().splitlines()\n",
    "    if len(arq_dis3) != 0:\n",
    "        primeiro3 = arq_dis3[0].strip()\n",
    "        primeiro3 = primeiro3.split()\n",
    "        dfstable3.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro3[0]))+dias)\n",
    "    else:\n",
    "        dfstable3.append('Sim')\n",
    "        \n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df3 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df3['Configuração']=dfconfig3\n",
    "df3[r'$\\bar{a}$ (UA)']= dfabarra3\n",
    "#df3[r'$\\sigma _{a}$ (UA)']= dfdeltaa3\n",
    "#df3[r'e$_{ini}$']=dfeinicial3\n",
    "df3[r'e$_{max}$']=dfemax3\n",
    "df3['Estável']=dfstable3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab3 = open('tables/k56_mod2_M60.tex','w')\n",
    "tab3.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab3.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab3.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab3.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab3.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab3.write(r'\\begin{document}''\\n')\n",
    "tab3.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab3.write(df3.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab3.write(r'\\end{adjustbox}''\\n')\n",
    "tab3.write(r'\\end{document}''\\n')\n",
    "tab3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconfig4=[]\n",
    "dfabarra4 =[]\n",
    "dfdeltaa4 =[]\n",
    "dfeinicial4 = []\n",
    "dfemax4 = []\n",
    "dfstable4 = []\n",
    "caminho4=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r4 in arq[3]:\n",
    "    dfconfig4.append(r4.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "    leitura_arquivo4 = pd.read_csv(r4,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo4.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra4.append('{:.6f}'.format(np.mean(leitura_arquivo4['a'])))\n",
    "    #dfeinicial4.append(float(leitura_arquivo4['e'][0]))\n",
    "    dfemax4.append('{:.5f}'.format(max(leitura_arquivo4['e'])))\n",
    "#    dfdeltaa4.append('{:.3e}'.format(np.std(leitura_arquivo4['a'],ddof=1)))\n",
    "    caminho4.append(r4.split('f')[0])\n",
    "#    print(max(leitura_arquivo4['a']) - min(leitura_arquivo4['a']))\n",
    "for h4 in range(len(arq[3])):\n",
    "    with open(caminho4[h4]+'discard_mass.out') as dis4:\n",
    "        arq_dis4 = dis4.read().splitlines()\n",
    "    if len(arq_dis4) != 0:\n",
    "        primeiro4 = arq_dis4[0].strip()\n",
    "        primeiro4 = primeiro4.split()\n",
    "        dfstable4.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro4[0]))+dias)\n",
    "    else:\n",
    "        dfstable4.append('Sim')\n",
    "        \n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df4 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df4['Configuração']=dfconfig4\n",
    "df4[r'$\\bar{a}$ (UA)']= dfabarra4\n",
    "#df4[r'$\\sigma _{a}$ (UA)']= dfdeltaa4\n",
    "#df4[r'e$_{ini}$']=dfeinicial4\n",
    "df4[r'e$_{max}$']=dfemax4\n",
    "df4['Estável']=dfstable4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab4 = open('tables/k56_mod2_omega60.tex','w')\n",
    "tab4.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab4.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab4.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab4.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab4.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab4.write(r'\\begin{document}''\\n')\n",
    "tab4.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab4.write(df4.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab4.write(r'\\end{adjustbox}''\\n')\n",
    "tab4.write(r'\\end{document}''\\n')\n",
    "tab4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconfig5=[]\n",
    "dfabarra5 =[]\n",
    "dfdeltaa5 =[]\n",
    "dfeinicial5 = []\n",
    "dfemax5 = []\n",
    "dfstable5 = []\n",
    "caminho5=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r5 in arq[4]:\n",
    "    dfconfig5.append(r5.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "    leitura_arquivo5 = pd.read_csv(r5,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo5.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra5.append('{:.6f}'.format(np.mean(leitura_arquivo5['a'])))\n",
    "    #dfeinicial5.append(float(leitura_arquivo5['e'][0]))\n",
    "    dfemax5.append('{:.5f}'.format(max(leitura_arquivo5['e'])))\n",
    "#    dfdeltaa5.append('{:.3e}'.format(np.std(leitura_arquivo5['a'],ddof=1)))\n",
    "    caminho5.append(r5.split('f')[0])\n",
    "#    print(max(leitura_arquivo5['a']) - min(leitura_arquivo5['a']))\n",
    "for h5 in range(len(arq[4])):\n",
    "    with open(caminho5[h5]+'discard_mass.out') as dis5:\n",
    "        arq_dis5 = dis5.read().splitlines()\n",
    "    if len(arq_dis5) != 0:\n",
    "        primeiro5 = arq_dis5[0].strip()\n",
    "        primeiro5 = primeiro5.split()\n",
    "        dfstable5.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro5[0]))+dias)\n",
    "    else:\n",
    "        dfstable5.append('Sim')\n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df5 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df5['Configuração']=dfconfig5\n",
    "df5[r'$\\bar{a}$ (UA)']= dfabarra5\n",
    "#df5[r'$\\sigma _{a}$ (UA)']= dfdeltaa5\n",
    "#df5[r'e$_{ini}$']=dfeinicial5\n",
    "df5[r'e$_{max}$']=dfemax5\n",
    "df5['Estável']=dfstable5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab5 = open('tables/k9_M60.tex','w')\n",
    "tab5.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab5.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab5.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab5.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab5.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab5.write(r'\\begin{document}''\\n')\n",
    "tab5.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab5.write(df5.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab5.write(r'\\end{adjustbox}''\\n')\n",
    "tab5.write(r'\\end{document}''\\n')\n",
    "tab5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconfig6=[]\n",
    "dfabarra6 =[]\n",
    "dfdeltaa6 =[]\n",
    "dfeinicial6 = []\n",
    "dfemax6 = []\n",
    "dfstable6 = []\n",
    "caminho6=[]\n",
    "#Havia encontrado os arquivos follow, agora utilizará os caminhos que precedem follow para encontrar os arquivos discard\n",
    "for r6 in arq[5]:\n",
    "    dfconfig6.append(r6.split('/')[3].replace(r'_', r'\\underline{\\space}'))\n",
    "    leitura_arquivo6 = pd.read_csv(r6,delim_whitespace=True,header =None,engine='c')\n",
    "    leitura_arquivo6.columns=['t','a','e','i','capom','omega','capm','peri','apo','obar']\n",
    "    dfabarra6.append('{:.6f}'.format(np.mean(leitura_arquivo6['a'])))\n",
    "    #dfeinicial6.append(float(leitura_arquivo6['e'][0]))\n",
    "    dfemax6.append('{:.6f}'.format(max(leitura_arquivo6['e'])))\n",
    "#    dfdeltaa6.append('{:.3e}'.format(np.std(leitura_arquivo6['a'],ddof=1)))\n",
    "    caminho6.append(r6.split('f')[0])\n",
    "#    print(max(leitura_arquivo6['a']) - min(leitura_arquivo6['a']))\n",
    "for h6 in range(len(arq[5])):\n",
    "    with open(caminho6[h6]+'discard_mass.out') as dis6:\n",
    "        arq_dis6 = dis6.read().splitlines()\n",
    "    if len(arq_dis6) != 0:\n",
    "        primeiro6 = arq_dis6[0].strip()\n",
    "        primeiro6 = primeiro6.split()\n",
    "        dfstable6.append('Nao - Expulsão em '+'{:.2e}'.format(float(primeiro6[0]))+dias)\n",
    "    else:\n",
    "        dfstable6.append('Sim')\n",
    "        \n",
    "        \n",
    "columns=['Configuração',r'$\\bar{a}$ (UA)',r'e$_{max}$','Estável']\n",
    "index =[''] + ['Caso 1'] +['']*3 + ['Caso 2'] + ['']*3+['Caso3']+['']*2\n",
    "df6 = pd.DataFrame(columns=columns,index =index)\n",
    "\n",
    "df6['Configuração']=dfconfig6\n",
    "df6[r'$\\bar{a}$ (UA)']= dfabarra6\n",
    "#df6[r'$\\sigma _{a}$ (UA)']= dfdeltaa6\n",
    "#df6[r'e$_{ini}$']=dfeinicial6\n",
    "df6[r'e$_{max}$']=dfemax6\n",
    "df6['Estável']=dfstable6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab6 = open('tables/k9_omega60.tex','w')\n",
    "tab6.write(r'\\documentclass[11pt, a4paper]{article}''\\n')\n",
    "tab6.write(r'\\usepackage[utf8]{inputenc}''\\n')\n",
    "tab6.write(r'\\usepackage[portuguese]{babel}''\\n')\n",
    "tab6.write(r'\\usepackage{booktabs}''\\n') \n",
    "tab6.write(r'\\usepackage{adjustbox}''\\n')\n",
    "tab6.write(r'\\begin{document}''\\n')\n",
    "tab6.write(r'\\begin{adjustbox}{max width=\\textwidth}''\\n')\n",
    "tab6.write(df6.to_latex(escape=False).replace(r'\\toprule',r'\\hline').replace(r'\\midrule',r'\\hline').replace(r'\\bottomrule',r'\\hline'))\n",
    "tab6.write(r'\\end{adjustbox}''\\n')\n",
    "tab6.write(r'\\end{document}''\\n')\n",
    "tab6.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
